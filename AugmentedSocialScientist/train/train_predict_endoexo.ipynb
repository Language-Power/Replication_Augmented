{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a definitive model, log it and predict golden standard\n",
    "\n",
    "## Paths import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#sys.path.append(os.path.realpath('./AugmentedSocialScientist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your current working directory (cwd) is `ReproducingAugSS/AugmentedSocialScientist/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PATHS import ENDOEXO_ASS, ENDOEXO_GS, SAVED_MODELS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS_OFF = 5\n",
    "SAMPLER_OFF = \"random\"\n",
    "LR_OFF = 5e-5\n",
    "BS_OFF = 32\n",
    "\n",
    "N_EPOCHS_ENDOEXO = 25\n",
    "SAMPLER_ENDOEXO = \"sequential\"\n",
    "LR_ENDOEXO = 1e-5\n",
    "BS_ENDOEXO = 64\n",
    "\n",
    "DROP_DUPLICATES = True\n",
    "PERCENT_OF_DATA = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /pbs/home/r/rshen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from TransferSociologist.data import Dataset\n",
    "from TransferSociologist.models import BertClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_experiment(\n",
    "    train_path, gs_path, drop_duplicates=False, percent_of_data=1\n",
    "):\n",
    "    dataset = Dataset()\n",
    "    dataset.read(\n",
    "        data_path=train_path, gold_standard_path=gs_path, data_type=\"csv\"\n",
    "    )\n",
    "    dataset.df = dataset.df.rename({'is_control_1': 'is_control'}, axis=1)\n",
    "    if drop_duplicates == True:\n",
    "        if \"is_control\" in dataset.df.columns:\n",
    "            gs = dataset.df[dataset.df.is_gold_standard == True]\n",
    "            no_gs = dataset.df[dataset.df.is_gold_standard == False]\n",
    "            no_gs = pd.concat(\n",
    "                [\n",
    "                    no_gs[no_gs.is_control == True]\n",
    "                        .groupby([\"text\"])\n",
    "                        .apply(lambda x: x.sample(1))\n",
    "                        .reset_index(drop=True),\n",
    "                    no_gs[no_gs.is_control != True]\n",
    "                ]\n",
    "            )\n",
    "            dataset.df = pd.concat([gs, no_gs])\n",
    "\n",
    "    dataset.task_encode(\n",
    "        task_type=\"sentence_classification\", bert_model=\"CamemBert\"\n",
    "    )\n",
    "    # natural_samples = dataset.df\n",
    "    # Now sample subset of data\n",
    "    gs = dataset.df[dataset.df.is_gold_standard == True]\n",
    "    no_gs = dataset.df[dataset.df.is_gold_standard == False]\n",
    "    no_gs = no_gs.sample(frac=percent_of_data)\n",
    "    dataset.df = pd.concat([no_gs, gs])\n",
    "    dataset.encode_torch(\n",
    "        task_type=\"sentence_classification\",\n",
    "        bert_model=\"CamemBert\",\n",
    "        # test_size=0.3,\n",
    "        random_seed=2018,\n",
    "    )\n",
    "\n",
    "    dataset_pred = Dataset()\n",
    "    dataset_pred.read(data_path=gs_path, data_type=\"csv\")\n",
    "    dataset_pred.task_encode(\n",
    "        task_type=\"sentence_classification\",\n",
    "        bert_model=\"CamemBert\",\n",
    "        # pred_gs=True,\n",
    "        pred_mode=True,\n",
    "    )\n",
    "    dataset_pred.encode_torch(\n",
    "        task_type=\"sentence_classification\",\n",
    "        bert_model=\"CamemBert\",\n",
    "        pred_mode=True,\n",
    "    )\n",
    "    dataset_pred.df.head()\n",
    "    return dataset, dataset_pred\n",
    "\n",
    "\n",
    "def run_experiment(dataset, dataset_pred, batch_size, lr, sampler, nepochs):\n",
    "    clf = BertClassifier()\n",
    "    random_seed = np.random.randint(2021)\n",
    "\n",
    "    perfs, _, epoch_best = clf.fit_evaluate(\n",
    "        dataset.train,\n",
    "        dataset.test,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        nepochs=nepochs,\n",
    "        random_seed=random_seed,\n",
    "        learning_rate=lr,\n",
    "    )\n",
    "    perf_dic = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": lr,\n",
    "        \"sampler\": sampler,\n",
    "        \"nepochs\": nepochs,\n",
    "        \"best epoch\": int(epoch_best),\n",
    "        \"random_seed\": int(random_seed),\n",
    "        \"train_size\": len(dataset.train[0])\n",
    "    }\n",
    "    inv_conv_dict = {\n",
    "        item: key\n",
    "        for i, (key, item) in enumerate(dataset.conversion_dict.items())\n",
    "    }\n",
    "    for i in range(len(perfs[0])):\n",
    "        j = inv_conv_dict[i]\n",
    "        perf_dic[f\"prec_tok_{j}\"] = float(perfs[0][i])\n",
    "        perf_dic[f\"rec_tok_{j}\"] = float(perfs[1][i])\n",
    "        perf_dic[f\"F1_tok_{j}\"] = float(perfs[2][i])\n",
    "        perf_dic[f\"supp_tok_{j}\"] = float(perfs[3][i])\n",
    "        # perf_dic[f'prec_{j}_best_run'] = float(best_perfs[0][i])\n",
    "        # perf_dic[f'rec_{j}_best_run'] = float(best_perfs[1][i])\n",
    "        # perf_dic[f'F1_{j}_best_run'] = float(best_perfs[2][i])\n",
    "\n",
    "    # Now, predict\n",
    "    labels, logits = clf.predict(dataset_pred.pred)\n",
    "\n",
    "    dataset_pred.df[\"labels_pred\"] = labels\n",
    "    dataset_pred.df[\"labels_pred\"] = dataset_pred.df[\"labels_pred\"].apply(\n",
    "        lambda x: inv_conv_dict[x]\n",
    "    )\n",
    "    dataset_pred.df[\"logits\"] = logits\n",
    "    dataset_pred.df[\"pred_labels\"] = dataset_pred.df.apply(\n",
    "        lambda x: [[x.spans[0], x.spans[1], x.labels_pred]], axis=1\n",
    "    )\n",
    "    cleaned_preds = (\n",
    "        dataset_pred.df.groupby(dataset_pred.df.text)\n",
    "        .agg({\"pred_labels\": \"sum\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    preds = pd.merge(\n",
    "        cleaned_preds,\n",
    "        dataset_pred.df[[\"text\", \"labels\"]].drop_duplicates(),\n",
    "        left_on=\"text\",\n",
    "        right_on=\"text\",\n",
    "    )\n",
    "    preds[\"labels_str\"] = preds.text.apply(lambda x: [0] * len(x))\n",
    "    preds[\"labels_pred_str\"] = preds.text.apply(lambda x: [0] * len(x))\n",
    "    preds[\"labels_str\"] = preds.apply(\n",
    "        lambda x: fill_zeros(x.labels, x.labels_str, dataset.conversion_dict),\n",
    "        axis=1,\n",
    "    )\n",
    "    preds[\"labels_pred_str\"] = preds.apply(\n",
    "        lambda x: fill_zeros(\n",
    "            x.pred_labels, x.labels_pred_str, dataset.conversion_dict\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    true = reduce(add, preds[\"labels_str\"].values)\n",
    "    pred = reduce(add, preds[\"labels_pred_str\"].values)\n",
    "    perfs_char = precision_recall_fscore_support(true, pred)\n",
    "    for i in range(len(perfs_char[0])):\n",
    "        j = inv_conv_dict[i]\n",
    "        perf_dic[f\"prec_char_{j}\"] = float(perfs_char[0][i])\n",
    "        perf_dic[f\"rec_char_{j}\"] = float(perfs_char[1][i])\n",
    "        perf_dic[f\"F1_char_{j}\"] = float(perfs_char[2][i])\n",
    "        perf_dic[f\"supp_char_{j}\"] = float(perfs_char[3][i])\n",
    "    return perf_dic, dataset_pred, clf\n",
    "\n",
    "\n",
    "def fill_zeros(labels, zeros, conv_dict):\n",
    "    try:\n",
    "        labels = eval(labels)\n",
    "    except:\n",
    "        pass\n",
    "    for l in labels:\n",
    "        start_span, stop_span, lab = l\n",
    "        size = stop_span - start_span\n",
    "        number = conv_dict[lab]\n",
    "        zeros[start_span:stop_span] = [number] * size\n",
    "    return zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from torch.cuda import empty_cache\n",
    "\n",
    "def process(params, paths, percent_of_data=1):\n",
    "    train_path, gs_path = paths\n",
    "    dataset, dataset_pred = prepare_experiment(\n",
    "        train_path, gs_path, params[\"drop_duplicates\"], percent_of_data\n",
    "    )\n",
    "    p = run_experiment(\n",
    "        dataset,\n",
    "        dataset_pred,\n",
    "        params[\"batch_size\"],\n",
    "        params[\"lr\"],\n",
    "        params[\"sampler\"],\n",
    "        params[\"nepochs\"],\n",
    "    )\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gold standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.46      0.61       149\n",
      "         1.0       0.57      0.96      0.72       179\n",
      "         2.0       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.64       377\n",
      "   macro avg       0.49      0.47      0.44       377\n",
      "weighted avg       0.62      0.64      0.58       377\n",
      "\n",
      "\n",
      "======== Epoch 2 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.83      0.73       149\n",
      "         1.0       0.68      0.72      0.70       179\n",
      "         2.0       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.67       377\n",
      "   macro avg       0.44      0.51      0.48       377\n",
      "weighted avg       0.58      0.67      0.62       377\n",
      "\n",
      "\n",
      "======== Epoch 3 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/pbs/home/r/rshen/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.86      0.75       149\n",
      "         1.0       0.72      0.75      0.74       179\n",
      "         2.0       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.69       377\n",
      "   macro avg       0.46      0.54      0.50       377\n",
      "weighted avg       0.61      0.69      0.65       377\n",
      "\n",
      "\n",
      "======== Epoch 4 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.83      0.76       149\n",
      "         1.0       0.74      0.79      0.76       179\n",
      "         2.0       0.83      0.20      0.33        49\n",
      "\n",
      "    accuracy                           0.73       377\n",
      "   macro avg       0.76      0.61      0.62       377\n",
      "weighted avg       0.74      0.73      0.71       377\n",
      "\n",
      "\n",
      "======== Epoch 5 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.83      0.78       149\n",
      "         1.0       0.78      0.79      0.79       179\n",
      "         2.0       0.81      0.45      0.58        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.78      0.69      0.72       377\n",
      "weighted avg       0.77      0.76      0.76       377\n",
      "\n",
      "\n",
      "======== Epoch 6 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74       149\n",
      "         1.0       0.75      0.82      0.78       179\n",
      "         2.0       0.71      0.45      0.55        49\n",
      "\n",
      "    accuracy                           0.74       377\n",
      "   macro avg       0.73      0.67      0.69       377\n",
      "weighted avg       0.74      0.74      0.73       377\n",
      "\n",
      "\n",
      "======== Epoch 7 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.74      0.75       149\n",
      "         1.0       0.76      0.83      0.79       179\n",
      "         2.0       0.68      0.51      0.58        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.69      0.71       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 8 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.77       149\n",
      "         1.0       0.78      0.81      0.79       179\n",
      "         2.0       0.65      0.49      0.56        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.73      0.69      0.71       377\n",
      "weighted avg       0.75      0.76      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 9 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.85      0.78       149\n",
      "         1.0       0.82      0.75      0.78       179\n",
      "         2.0       0.67      0.49      0.56        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.74      0.70      0.71       377\n",
      "weighted avg       0.76      0.76      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 10 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.79      0.76       149\n",
      "         1.0       0.78      0.79      0.78       179\n",
      "         2.0       0.67      0.49      0.56        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.69      0.70       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 11 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.77      0.75       149\n",
      "         1.0       0.76      0.79      0.78       179\n",
      "         2.0       0.68      0.51      0.58        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.69      0.70       377\n",
      "weighted avg       0.74      0.75      0.74       377\n",
      "\n",
      "\n",
      "======== Epoch 12 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.77      0.75       149\n",
      "         1.0       0.77      0.79      0.78       179\n",
      "         2.0       0.68      0.51      0.58        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.69      0.70       377\n",
      "weighted avg       0.74      0.75      0.74       377\n",
      "\n",
      "\n",
      "======== Epoch 13 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epoch took: 0:00:31\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.79      0.76       149\n",
      "         1.0       0.79      0.78      0.78       179\n",
      "         2.0       0.68      0.57      0.62        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.71      0.72       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 14 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.76       149\n",
      "         1.0       0.78      0.79      0.78       179\n",
      "         2.0       0.68      0.55      0.61        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.71      0.72       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 15 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.75      0.76       149\n",
      "         1.0       0.77      0.82      0.79       179\n",
      "         2.0       0.67      0.57      0.62        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.74      0.71      0.72       377\n",
      "weighted avg       0.76      0.76      0.76       377\n",
      "\n",
      "\n",
      "======== Epoch 16 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.78      0.76       149\n",
      "         1.0       0.78      0.78      0.78       179\n",
      "         2.0       0.68      0.55      0.61        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.70      0.71       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 17 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.77      0.76       149\n",
      "         1.0       0.77      0.82      0.79       179\n",
      "         2.0       0.68      0.53      0.60        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.74      0.70      0.72       377\n",
      "weighted avg       0.76      0.76      0.76       377\n",
      "\n",
      "\n",
      "======== Epoch 18 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.76       149\n",
      "         1.0       0.77      0.80      0.79       179\n",
      "         2.0       0.68      0.51      0.58        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.70      0.71       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 19 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77       149\n",
      "         1.0       0.77      0.83      0.80       179\n",
      "         2.0       0.68      0.53      0.60        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.74      0.71      0.72       377\n",
      "weighted avg       0.76      0.76      0.76       377\n",
      "\n",
      "\n",
      "======== Epoch 20 / 25 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.78      0.76       149\n",
      "         1.0       0.77      0.79      0.78       179\n",
      "         2.0       0.68      0.51      0.58        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.69      0.71       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 21 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epoch took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.77       149\n",
      "         1.0       0.78      0.80      0.79       179\n",
      "         2.0       0.68      0.53      0.60        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.74      0.70      0.72       377\n",
      "weighted avg       0.76      0.76      0.76       377\n",
      "\n",
      "\n",
      "======== Epoch 22 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epoch took: 0:00:31\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.77       149\n",
      "         1.0       0.78      0.80      0.79       179\n",
      "         2.0       0.68      0.53      0.60        49\n",
      "\n",
      "    accuracy                           0.76       377\n",
      "   macro avg       0.74      0.70      0.72       377\n",
      "weighted avg       0.76      0.76      0.76       377\n",
      "\n",
      "\n",
      "======== Epoch 23 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epoch took: 0:00:31\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.76       149\n",
      "         1.0       0.78      0.79      0.78       179\n",
      "         2.0       0.67      0.53      0.59        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.70      0.71       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 24 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epoch took: 0:00:31\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.80      0.76       149\n",
      "         1.0       0.78      0.77      0.77       179\n",
      "         2.0       0.67      0.53      0.59        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.73      0.70      0.71       377\n",
      "weighted avg       0.75      0.75      0.75       377\n",
      "\n",
      "\n",
      "======== Epoch 25 / 25 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epoch took: 0:00:31\n",
      "\n",
      "Running Validation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.79      0.76       149\n",
      "         1.0       0.78      0.77      0.77       179\n",
      "         2.0       0.67      0.53      0.59        49\n",
      "\n",
      "    accuracy                           0.75       377\n",
      "   macro avg       0.72      0.70      0.71       377\n",
      "weighted avg       0.74      0.75      0.74       377\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "empty_cache()\n",
    "tpath = ENDOEXO_ASS\n",
    "gs_path = ENDOEXO_GS\n",
    "params = {\n",
    "\"batch_size\": BS_ENDOEXO,\n",
    "\"nepochs\": N_EPOCHS_ENDOEXO,\n",
    "\"lr\": LR_ENDOEXO,\n",
    "\"sampler\": SAMPLER_ENDOEXO,\n",
    "\"drop_duplicates\": DROP_DUPLICATES,\n",
    "}\n",
    "percent = 1\n",
    "\n",
    "paths = tpath, gs_path\n",
    "exp_name = os.path.basename(tpath).replace(\n",
    "    \"_train\", \"\").replace('.csv', '')\n",
    "p, dataset_pred, clf = process(params, paths, percent)\n",
    "p[\"exp_name\"] = exp_name\n",
    "p[\"percent_of_data\"] = percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save(os.path.join(SAVED_MODELS_PATH, 'policy_politics_ASS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'lr': 1e-05,\n",
       " 'sampler': 'sequential',\n",
       " 'nepochs': 25,\n",
       " 'best epoch': 14,\n",
       " 'random_seed': 423,\n",
       " 'train_size': 2357,\n",
       " 'prec_tok_endogène': 0.7283950617283951,\n",
       " 'rec_tok_endogène': 0.7919463087248322,\n",
       " 'F1_tok_endogène': 0.7588424437299035,\n",
       " 'supp_tok_endogène': 149.0,\n",
       " 'prec_tok_exogène': 0.7784090909090909,\n",
       " 'rec_tok_exogène': 0.7653631284916201,\n",
       " 'F1_tok_exogène': 0.771830985915493,\n",
       " 'supp_tok_exogène': 179.0,\n",
       " 'prec_tok_autre': 0.6666666666666666,\n",
       " 'rec_tok_autre': 0.5306122448979592,\n",
       " 'F1_tok_autre': 0.5909090909090909,\n",
       " 'supp_tok_autre': 49.0,\n",
       " 'prec_char_endogène': 0.7209515096065874,\n",
       " 'rec_char_endogène': 0.7971498944405349,\n",
       " 'F1_char_endogène': 0.7571383812010445,\n",
       " 'supp_char_endogène': 22736.0,\n",
       " 'prec_char_exogène': 0.8180124410253328,\n",
       " 'rec_char_exogène': 0.8008060720169452,\n",
       " 'F1_char_exogène': 0.8093178135545347,\n",
       " 'supp_char_exogène': 33992.0,\n",
       " 'prec_char_autre': 0.5477815699658704,\n",
       " 'rec_char_autre': 0.279454439930354,\n",
       " 'F1_char_autre': 0.37009992313604917,\n",
       " 'supp_char_autre': 3446.0,\n",
       " 'exp_name': 'endoexo_ass',\n",
       " 'percent_of_data': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
