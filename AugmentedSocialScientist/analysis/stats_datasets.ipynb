{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7cfd18",
   "metadata": {},
   "source": [
    "# Providing basic statistics on the dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "931dde46",
=======
   "execution_count": 2,
>>>>>>> eaebf18e7103ba961117f1d626714a66c4755a05
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import floor\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import statsmodels.stats.api as sms\n",
    "import sys\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from transformers import CamembertTokenizer\n",
    "\n",
    "# WARNING : Make sure that your current working directory (cwd) is `ReproducingAugSS/AugmentedSocialScientist/`\n",
    "\n",
    "\n",
    "from PATHS import OFF_ASS, OFF_3, OFF_34, OFF_GS\n",
    "from PATHS import ENDOEXO_ASS, ENDOEXO_3, ENDOEXO_34, ENDOEXO_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eee86261c224986bd32e4cb68754a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_char = 0\n",
    "for path in tqdm(glob(\"../../datasets/AugmentedSocialScientist/prediction_files/*\")):\n",
    "    total_char += pd.read_csv(path).texte.apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316093701"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'Policy vs. Politics training set':ENDOEXO_ASS,\n",
    "            'Off the Record training set':OFF_ASS,\n",
    "            'Policy vs. Politics gold standard': ENDOEXO_GS,\n",
    "            'Off the Record gold standard':OFF_GS\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy vs. Politics training set\n",
      "===\n",
      "n_texts: 63\n",
      "n_char: 383251 (0.12%)\n",
      "n_tokens: 86962\n",
      "\n",
      "Off the Record training set\n",
      "===\n",
      "n_texts: 6274\n",
      "n_char: 3160068 (1.00%)\n",
      "n_tokens: 759356\n",
      "\n",
      "Policy vs. Politics gold standard\n",
      "===\n",
      "n_texts: 11\n",
      "n_char: 60174 (0.02%)\n",
      "n_tokens: 13783\n",
      "\n",
      "Off the Record gold standard\n",
      "===\n",
      "n_texts: 639\n",
      "n_char: 316575 (0.10%)\n",
      "n_tokens: 77283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in datasets:\n",
    "    df = pd.read_csv(datasets[name])\n",
    "    print(name)\n",
    "    print('===')\n",
    "    print(f'n_texts: {df.shape[0]}')\n",
    "    print(f'n_char: {df.text.apply(len).sum()} ({df.text.apply(len).sum()/total_char:.2%})')\n",
    "    print(f'n_tokens: {df.text.apply(lambda x: len(tokenizer.encode(x))).sum()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2b04e",
   "metadata": {},
   "source": [
    "## Label distribution (character-wise statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac200914",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_paths = [OFF_ASS, OFF_3, OFF_34, OFF_GS]\n",
    "ee_paths = [ENDOEXO_ASS, ENDOEXO_3, ENDOEXO_34, ENDOEXO_GS]\n",
    "dfs_off = [pd.read_csv(path) for path in off_paths]\n",
    "dfs_endoexo = [pd.read_csv(path) for path in ee_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5dd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We deduplicate on sentences/articles that were control extract (i.e. multiple annotator annotated the extract)\n",
    "# To do so, we randomly draw one of the multiple annotation for a given control extract\n",
    "# We do this 100 times i.i.d. and give the estimate + conf interval\n",
    "\n",
    "def deduplicate(df):\n",
    "    df = df.rename({'is_control_1': 'is_control'}, axis=1)\n",
    "    if \"is_control\" in df.columns:\n",
    "        df = pd.concat([\n",
    "            df[df.is_control == True].groupby([\"text\"]).apply(lambda x: x.sample(1)).reset_index(drop=True),\n",
    "            df[df.is_control != True]]\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def sum_nb_char(ls, label):\n",
    "    s = 0\n",
    "    try:\n",
    "        ls = eval(ls)\n",
    "    except:\n",
    "        pass\n",
    "    if len(ls)==0:\n",
    "        return s\n",
    "    for l in ls:\n",
    "        if l[2] == label:\n",
    "            s = s+(l[1]-l[0])\n",
    "    return s\n",
    "\n",
    "\n",
    "def add_char_stats_ee(df):\n",
    "    df['nb_char'] = df['text'].apply(len)\n",
    "    df['nb_char_endogène'] = df['labels'].apply(lambda x: sum_nb_char(x, 'endogène'))\n",
    "    df['nb_char_exogène'] = df['labels'].apply(lambda x : sum_nb_char(x, 'exogène'))\n",
    "    df['nb_char_autre'] = df['labels'].apply(lambda x : sum_nb_char(x, 'autre'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_char_stats_off(df):\n",
    "    df['nb_char'] = df['text'].apply(len)\n",
    "    df['nb_char_off'] = df['labels'].apply(lambda x: sum_nb_char(x, 'off'))\n",
    "    return df\n",
    "\n",
    "\n",
    "df_stats_off = pd.DataFrame({\"total_off\": [], \"total_char\": [], 'exp':[]})\n",
    "df_stats_ee = pd.DataFrame({\"total_endo\": [], \"total_exo\": [], \"total_autre\": [], \"total_char\": [], 'exp':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f45739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c50e6e6e24e24b4e585684433dbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We deduplicate on sentences/articles that were control extract (i.e. multiple annotator annotated the extract)\n",
    "# To do so, we randomly draw one of the multiple annotation for a given control extract\n",
    "# We do this 100 times i.i.d. and give the estimate + conf interval\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    dedup_off = [deduplicate(df) for df in dfs_off]\n",
    "    dedup_ee = [deduplicate(df) for df in dfs_endoexo]\n",
    "    dedup_off = [add_char_stats_off(df) for df in dedup_off]\n",
    "    dedup_ee = [add_char_stats_ee(df) for df in dedup_ee]\n",
    "    for i, df in enumerate(dedup_off):\n",
    "        exp_name = os.path.basename(off_paths[i]).replace(\"_train\", \"\").replace('.csv', '')\n",
    "        df_stats_off = df_stats_off.append(\n",
    "            pd.DataFrame([[df.nb_char_off.sum(), df.nb_char.sum(), exp_name]], columns=[\"total_off\", \"total_char\", 'exp'])\n",
    "        )\n",
    "    for i, df in enumerate(dedup_ee):\n",
    "        exp_name = os.path.basename(ee_paths[i]).replace(\"_train\", \"\").replace('.csv', '')\n",
    "        df_stats_ee = df_stats_ee.append(\n",
    "            pd.DataFrame([[df.nb_char_endogène.sum(), df.nb_char_exogène.sum(), df.nb_char_autre.sum(), df.nb_char.sum(), exp_name]], columns=[\"total_endo\", \"total_exo\", \"total_autre\", \"total_char\", 'exp'])\n",
    "            )\n",
    "\n",
    "df_stats_off['off_perc'] = df_stats_off.apply(lambda x: 100*x.total_off/x.total_char, axis=1)\n",
    "df_stats_ee['endo_perc'] = df_stats_ee.apply(lambda x: 100*x.total_endo/x.total_char, axis=1)\n",
    "df_stats_ee['exo_perc'] = df_stats_ee.apply(lambda x: 100*x.total_exo/x.total_char, axis=1)\n",
    "df_stats_ee['autre_perc'] = df_stats_ee.apply(lambda x: 100*x.total_autre/x.total_char, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6346ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dist_pp = df_stats_ee.groupby('exp').aggregate(lambda g: sms.DescrStatsW(g).tconfint_mean())\n",
    "label_dist_pp.index = ['Research Assistants Train Set','Microworkers Train Set','Social Scientist Train Set','Gold_standard']\n",
    "label_dist_pp.columns = ['total_politics','total_policy','total_ohter','total_char','politics_perc','policy_perc','other_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f24ae00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Social Scientist Train Set</th>\n",
       "      <th>Research Assistants Train Set</th>\n",
       "      <th>Microworkers Train Set</th>\n",
       "      <th>Gold_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>politics_perc</th>\n",
       "      <td>(39.00472536275183, 39.00472536275183)</td>\n",
       "      <td>(35.48415626701069, 35.676091194835465)</td>\n",
       "      <td>(32.073386771863156, 32.604440552788304)</td>\n",
       "      <td>(37.67075481104796, 37.67075481104796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_perc</th>\n",
       "      <td>(55.41198848796219, 55.41198848796219)</td>\n",
       "      <td>(51.34769041605435, 51.520993553459135)</td>\n",
       "      <td>(54.729236447655474, 55.40319895368726)</td>\n",
       "      <td>(56.48951374347724, 56.48951374347724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_perc</th>\n",
       "      <td>(5.343234590385935, 5.343234590385935)</td>\n",
       "      <td>(10.792889910897877, 10.833887318646209)</td>\n",
       "      <td>(9.725072099228809, 9.918393932170977)</td>\n",
       "      <td>(5.726725828430883, 5.726725828430883)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Social Scientist Train Set  \\\n",
       "politics_perc  (39.00472536275183, 39.00472536275183)   \n",
       "policy_perc    (55.41198848796219, 55.41198848796219)   \n",
       "other_perc     (5.343234590385935, 5.343234590385935)   \n",
       "\n",
       "                          Research Assistants Train Set  \\\n",
       "politics_perc   (35.48415626701069, 35.676091194835465)   \n",
       "policy_perc     (51.34769041605435, 51.520993553459135)   \n",
       "other_perc     (10.792889910897877, 10.833887318646209)   \n",
       "\n",
       "                                 Microworkers Train Set  \\\n",
       "politics_perc  (32.073386771863156, 32.604440552788304)   \n",
       "policy_perc     (54.729236447655474, 55.40319895368726)   \n",
       "other_perc       (9.725072099228809, 9.918393932170977)   \n",
       "\n",
       "                                        Gold_standard  \n",
       "politics_perc  (37.67075481104796, 37.67075481104796)  \n",
       "policy_perc    (56.48951374347724, 56.48951374347724)  \n",
       "other_perc     (5.726725828430883, 5.726725828430883)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dist_pp.loc[['Social Scientist Train Set','Research Assistants Train Set','Microworkers Train Set','Gold_standard'],['politics_perc','policy_perc','other_perc']].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e39abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dist_off = df_stats_off.groupby('exp').aggregate(lambda g: sms.DescrStatsW(g).tconfint_mean())\n",
    "label_dist_off.index = ['Microworkers Train Set','Research Assistants Train Set','Social Scientist Train Set','Gold_standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10c1a14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Social Scientist Train Set</th>\n",
       "      <th>Research Assistants Train Set</th>\n",
       "      <th>Microworkers Train Set</th>\n",
       "      <th>Gold_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>off_perc</th>\n",
       "      <td>(2.4786175487362927, 2.4786175487362927)</td>\n",
       "      <td>(3.353414104639324, 3.3574820441772126)</td>\n",
       "      <td>(4.276981389316012, 4.284881328797855)</td>\n",
       "      <td>(2.976861723130379, 2.976861723130379)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Social Scientist Train Set  \\\n",
       "off_perc  (2.4786175487362927, 2.4786175487362927)   \n",
       "\n",
       "                    Research Assistants Train Set  \\\n",
       "off_perc  (3.353414104639324, 3.3574820441772126)   \n",
       "\n",
       "                          Microworkers Train Set  \\\n",
       "off_perc  (4.276981389316012, 4.284881328797855)   \n",
       "\n",
       "                                   Gold_standard  \n",
       "off_perc  (2.976861723130379, 2.976861723130379)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dist_off.loc[['Social Scientist Train Set','Research Assistants Train Set','Microworkers Train Set','Gold_standard'],['off_perc']].transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
